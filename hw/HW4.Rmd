---
title: "Untitled"
author: "Neal Marquez"
date: "November 5, 2018"
output: pdf_document
---

```{r setup, message=FALSE, warning=FALSE}
rm(list=ls())
library(MASS)
library(tidyverse)
library(mvtnorm)
library(latex2exp)

anesDF <- "https://faculty.washington.edu/cadolph/mle/nes92con.csv" %>%
    read_csv

llk.oprobit.new <- function(param, formula, data){
    x <- model.matrix(formula[-2], data=data)
    y <- unlist(data[,all.vars(formula)[1]])
    yVals <- sort(unique(y))
    yMat <- sapply(yVals, function(xi) xi == y)
    b <- param[1:ncol(x)]
    xb <- x%*%b
    taus <- c(0, param[(ncol(x)+1):length(param)])
    pMatrix <- matrix(0, nrow=nrow(x), ncol=length(taus) + 1)
    i <- 1
    pMatrix[,i] <- log(pnorm(-xb))
    for(t in taus[2:length(taus)]){
        i <- i + 1
        tlag <- taus[i-1]
        if(t <= tlag){
            pMatrix[,i] <- -(abs(t)*10000) 
        }
        else{
            pMatrix[,i] <- log(pnorm(t-xb)-pnorm(tlag-xb))
        }
    }
    pMatrix[,i+1] <- log(1-pnorm(t-xb))

    -sum(pMatrix * yMat)
}

oprobit.fit <- function(formula, data){
    xN <- ncol(model.matrix(formula[-2], data=data))
    yN <- length(unique(unlist(data[,all.vars(formula)[1]])))
    tauStarts <- 1:(yN-2)
    names(tauStarts) <- paste0("tau", 2:(yN-1)) 

    pStart <- c(coef(lm(formula, data=data)), tauStarts)
    optFit <- optim(
        pStart,
        llk.oprobit.new,
        method = "BFGS",
        formula = formula,
        data = data,
        hessian = TRUE)
    optFit$formula <- formula
    optFit
}

modelPredict <- function(model, data, draws=NULL){
    x <- model.matrix(model$formula[-2], data=data)
    yN <- length(model$par) - ncol(x) + 2
    if(is.null(draws)){
        draws_ <- 1
        paramDraws <- matrix(model$par, nrow=draws_, ncol=length(model$par))
        xb <- x %*% paramDraws[,1:ncol(x)]
        tdraws <- matrix(
            c(0, paramDraws[,(ncol(x) + 1):length(model$par)]), ncol=1)
    }
    else{
        draws_ <- draws
        paramDraws <- rmvnorm(draws, model$par, solve(model$hessian))
        xb <- x %*% t(paramDraws[,1:ncol(x)])
        tdraws <- t(cbind(0, paramDraws[,(ncol(x) + 1):length(model$par)]))
    }
    pArray <- array(0, dim=c(nrow(x), yN, draws_))
    for(d in 1:draws_){
        taus <- tdraws[,d]
        i <- 1
        pArray[,i,d] <- pnorm(-xb[,d])
        for(t in taus[2:length(taus)]){
            i <- i + 1
            tlag <- taus[i-1]
            pArray[,i,d] <- pnorm(t-xb[,d])-pnorm(tlag-xb[,d])
        }
        pArray[,i+1,d] <- 1-pnorm(t-xb[,d])
    }
    if(is.null(draws)){
        pArray <- pArray[,,1]
    }
    pArray
}

polrPredict <- function(model, data, draws=NULL){
    X <- model.matrix(update.formula(model$formula[-2], ~ . + 0), data=data)
    if(is.null(draws)){
        pArray <- t(sapply(c(X %*% model$coefficients), function(eta){
            diff(c(0,arm::invlogit(model$zeta - eta), 1))}))
    }
    else{
        pArray <- array(0, dim=c(nrow(X), length(model$zeta) + 1, draws))
        for(d in 1:draws){
            parMeans <- c(model$coefficients, model$zeta)
            bDraws <- rmvnorm(draws, parMeans, vcov(model))
            m_ <- list(
                formula = model$formula,
                coefficients = bDraws[d,1:ncol(X)],
                zeta = bDraws[d,(ncol(X)+1):ncol(bDraws)]
            )
            pArray[,,d] <- polrPredict(m_, data, draws=NULL)
        }
    }
    pArray
}
```

# A
Use an ordered probit model to explain respondents approval of Bush. Using the `llk.oprobit()` function provided in class and `optim()`, fit the model to the variable _bushapp_ with _milforce_, _rbdist_, _econ_, _partyid_, and _yrsofed_ as the only covariates. Report the estimated parameters, their standard errors, and the value of the log likelihood at its maximum.

```{r}
fog <- bushapp ~ milforce + rbdist + econ + partyid + yrsofed
modelFit <- oprobit.fit(fog, na.omit(anesDF[,all.vars(fog)]))
cat(paste0("Log Likelihood at the maximum: ", round(-modelFit$value, 4)))
tibble(
    Parameter = names(modelFit$par),
    Estimate = modelFit$par,
    std.err = diag(solve(modelFit$hessian))
)

```

# B
Calculate the probabilities that a respondent who identified themselves as a strong Democrat ( _partyid_ = -3) said they "Strongly Disapproved", "Disapproved", "Approved", or "Strongly Approved" of President Bush given their support or opposition to military force ( _milforce_ = $\{1, 2, 3, 4, 5\}$), holding the remaining covariates at their mean values.  Calculate the probabilities again over the same range of responses for _milforce_ for a respondent who identified themselves as a strong Republican ( _partyid_ = 3). You should have two sets of 20 probabilities, or 40 probabilities total.

```{r}
na.omit(anesDF[,all.vars(fog)]) %>%
    select(-bushapp, -milforce, -partyid) %>%
    summarise_all(mean) %>%
    cbind(expand.grid(milforce=1:5, partyid=c(-3, 3))) %>%
    cbind(round(modelPredict(modelFit, .), 4)) %>%
    select(milforce:`4`)
```

# C

Present the expected probabilities for each category you calculated in part b in a way that would not require your reader to know anything about ordered probit models. Be sure to present confidence intervals, in a fashion of your choosing.

```{r}
nDraws <- 1000
dataMat <- na.omit(anesDF[,all.vars(fog)]) %>%
    select(-bushapp, -milforce, -partyid) %>%
    summarise_all(mean) %>%
    cbind(expand.grid(milforce=1:5, partyid=c(-3, 3)))

simArray <- modelPredict(modelFit, dataMat, draws = nDraws)

bind_rows(lapply(1:nDraws, function(d){
    bind_rows(lapply(1:4, function(x) mutate(dataMat, bushapp=x))) %>%
        mutate(draw=d)})) %>%
    mutate(value=c(simArray)) %>%
    group_by(milforce, partyid, bushapp) %>%
    summarize(
        prob = mean(value),
        plwr = quantile(value, probs=.025),
        pupr = quantile(value, probs=.975)) %>%
    mutate(bushapp=as.factor(bushapp)) %>%
    mutate(Politics=if_else(
        partyid == 3, 
        "Strongly Republican",
        "Strongly Democrat")) %>%
    ggplot(aes(
        x=milforce, y=prob, group=bushapp, fill=bushapp, color=bushapp,
        ymin=plwr, ymax=pupr)) +
    geom_line() +
    geom_ribbon(alpha=.2) +
    theme_classic() +
    facet_wrap(~Politics) +
    labs(color="Bush\nApproval", fill="Bush\nApproval",
         x="Opposition to Military Force Support", y="Probability")
```

# D

In this part, you are asked to summarize the model estimated in part a. using just two simulated first differences. You may not alter the model itself to eliminate or collapse categories, as this would throw away useful information. __i.__ Simulate the increase in probability of either approving or strongly approving of Bush given a shift from strong opposition to the use of force to strong support for a respondent who is a strong Democrat and otherwise average. Provide a 95% confidence interval. __ii.__ Simulate the increase in probability of either approving or strongly approving of Bush given a shift from strong opposition to the use of force to strong support for a respondent who is a strong Republican and otherwise average. Provide a 95% confidence interval.

```{r}
bind_rows(lapply(1:nDraws, function(d){
    bind_rows(lapply(1:4, function(x) mutate(dataMat, bushapp=x))) %>%
        mutate(draw=d)})) %>%
    mutate(value=c(simArray)) %>%
    mutate(hiApp=bushapp >= 3) %>%
    filter(milforce %in% c(1,4) & hiApp) %>%
    group_by(partyid, draw, milforce) %>%
    summarize(value=sum(value)) %>%
    summarize(deltap=nth(value, 1) - nth(value, 2)) %>%
    group_by(partyid) %>%
    summarize(
        dprob = mean(deltap),
        dplwr = quantile(deltap, probs=.025),
        dpupr = quantile(deltap, probs=.975)) %>%
    mutate(Politics=if_else(
        partyid == 3, 
        "Strongly Republican",
        "Strongly Democrat")) %>%
    mutate(Politics=factor(
        Politics, 
        levels = c("Strongly Republican", "Strongly Democrat"))) %>%
    ggplot(aes(x=Politics, y=dprob, ymin=dplwr, ymax=dpupr, color=Politics)) +
    geom_point() +
    geom_errorbar(width=.2) +
    theme_classic() +
    labs(y=TeX("$\\Delta$ Probability"), x="") +
    guides(color=FALSE) +
    ggtitle(paste(
        "Increase in Approval and Strong Approval Probability",
        "of Bush with Change In Approval of Military Force", sep="\n"))
```

# E
Based upon your work above, briefly discuss of the results of the model.

# F
The `llk.oprobit()` function is written for ordered data with four categories. Alter the function so that it can be used to estimate a three category ordered probit. Using `R`, create a new variable _econ3_ which collapses _econ_ into a three-category variable. 1 Fit a model to the variable econ3 with _partyid_ as the only covariates to see the effect of an individual's party id on their perception of the economy.  Simply run the model and report the estimated parameters. Perform this fit using your altered function and `optim()`. Bonus [+10 points]: Modify the likelihood function so that it works generically for any number of categories.

```{r, warning=FALSE, message=FALSE}
econDF <- anesDF %>%
    mutate(econ3=as.factor(c(1, 1, 2, 3, 3)[econ])) %>%
    select(econ3, partyid) %>%
    na.omit

eForm <- econ3 ~ partyid
modelEconFit <- oprobit.fit(eForm, econDF)
tibble(
    Parameter = names(modelEconFit$par),
    Estimate = modelEconFit$par,
    std.err = diag(solve(modelEconFit$hessian))
)
```

```{r, warning=FALSE, message=FALSE}
pModel <- polr(eForm, data=econDF, Hess=TRUE)
pModel$formula <- eForm

pEconDF <- unique(select(econDF, partyid))

econDrawDF <- bind_rows(
    bind_rows(lapply(1:nDraws, function(d){
        bind_rows(lapply(1:3, function(x) mutate(pEconDF, econ3=x))) %>%
            mutate(draw=d)})) %>%
        mutate(value=c(modelPredict(modelEconFit, pEconDF, draws=nDraws))) %>%
        mutate(Model="Optim"),
    bind_rows(lapply(1:nDraws, function(d){
        bind_rows(lapply(1:3, function(x) mutate(pEconDF, econ3=x))) %>%
            mutate(draw=d)})) %>%
        mutate(value=c(polrPredict(pModel, pEconDF, draws=nDraws))) %>%
        mutate(Model="Polr"))

econDrawDF %>%
    group_by(partyid, econ3, Model) %>%
    summarize(
        prob = mean(value),
        plwr = quantile(value, probs=.025),
        pupr = quantile(value, probs=.975)) %>%
    ungroup %>%
    mutate(econ3=as.factor(econ3)) %>%
    ggplot(aes(
        x=partyid, y=prob, group=econ3, fill=econ3, color=econ3,
        ymin=plwr, ymax=pupr)) +
    geom_line() +
    geom_ribbon(alpha=.2) +
    theme_classic() +
    facet_wrap(~Model) +
    labs(color="Econ", fill="Econ",
         x="Party identification", y="Probability")

econDrawDF %>%
    filter(econ3 != 3) %>%
    group_by(partyid, Model, draw) %>%
    summarize(value=sum(value)) %>%
    summarize(
        dprob = mean(value),
        dplwr = quantile(value, probs=.025),
        dpupr = quantile(value, probs=.975)) %>%
    ggplot(aes(x=partyid, y=dprob, ymax=dpupr, ymin=dplwr)) +
    geom_line() +
    geom_ribbon(alpha=.2) +
    theme_classic() +
    facet_wrap(~Model) +
    labs(x="Party identification", y=TeX("Pr(Econ $\\neq$ 3)"))
```